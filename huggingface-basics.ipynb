{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "# Default model is distilbert-base-uncased-finetuned-sst-2-english\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "res = classifier([\"We are very happy to show you the HuggingFace Transformer library.\",\n",
    "                  \"We hope you don't hate it.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998084902763367}, {'label': 'NEGATIVE', 'score': 0.5308645963668823}]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific model (same in this case, nothing should change)\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "res = classifier([\"We are very happy to show you the HuggingFace Transformer library.\",\n",
    "                  \"We hope you don't hate it.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998084902763367}, {'label': 'NEGATIVE', 'score': 0.5308645963668823}]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts into list of tokens\n",
    "tokens = tokenizer.tokenize(\"We are very happy to show you the HuggingFace Transformer library\")\n",
    "\n",
    "# Turns it into a list of token IDs (number representation of the words)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# Dictionary of expanded token_ids (inlcudes start, end, and other tokens) and attention mask\n",
    "input_ids = tokenizer(\"We are very happy to show you the HuggingFace Transformer library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tokens: ['we', 'are', 'very', 'happy', 'to', 'show', 'you', 'the', 'hugging', '##face', 'transform', '##er', 'library']\n",
      "Token IDs: [2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 17662, 12172, 10938, 2121, 3075]\n",
      "Input IDs: {'input_ids': [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 17662, 12172, 10938, 2121, 3075, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Tokens: {tokens}\")\n",
    "print(f\"Token IDs: {token_ids}\")\n",
    "print(f\"Input IDs: {input_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2057,  2024,  2200,  3407,  2000,  2265,  2017,  1996, 17662,\n",
      "         12172, 10938,  2121,  3075,  1012,   102],\n",
      "        [  101,  2057,  3246,  2017,  2123,  1005,  1056,  5223,  2009,  1012,\n",
      "           102,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "X_train = [\"We are very happy to show you the HuggingFace Transformer library.\",\n",
    "                  \"We hope you don't hate it.\"]\n",
    "\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-4.1426,  4.4177],\n",
      "        [ 0.0818, -0.0418]]), hidden_states=None, attentions=None)\n",
      "tensor([[1.9153e-04, 9.9981e-01],\n",
      "        [5.3086e-01, 4.6914e-01]])\n",
      "tensor([1, 0])\n",
      "['POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disable gradient updating and tracking for inference\n",
    "    outputs = model(**batch) # unpacks the values of the dictionary\n",
    "    print(outputs)\n",
    "    predictions = F.softmax(outputs.logits, dim=1)\n",
    "    print(predictions)\n",
    "    labels = torch.argmax(predictions, dim=1) # Could have just passed in outputs\n",
    "    print(labels)\n",
    "    labels = [model.config.id2label[label_id] for label_id in labels.tolist()]\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pretrained model\n",
    "save_directory = \"saved\"\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use models from huggingface.co/models\n",
    "model_name = \"oliverguhr/german-sentiment-bert\"\n",
    "\n",
    "# Load and save model\n",
    "# tokenizer.save_pretrained(save_directory)\n",
    "# model.save_pretrained(save_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 10210, 26679, 25832,  9535,  2368,  9413,  6914, 18477,   102,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  8695,  2162, 15571,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  8695, 21541, 11721,  2099, 27969, 11039, 15451,  2061,  9535,\n",
      "           102,     0,     0,     0],\n",
      "        [  101, 27969, 11039,  2061,  8040,  7317, 15937,  2102, 15536,  2063,\n",
      "          9413, 18367,  3388,   102],\n",
      "        [  101,  8695,  2162,  9535,   999,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,  9033,  2063,  6904,  8093,  2102, 16417, 24665, 26639,  8285,\n",
      "          1012,   102,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "X_train = [\"Mit keinem guten Ergenbis\", \"Das war unfair\", \"Das ist gar nicht mal so gut\",\n",
    "         \"nicht so schlecht wie erwartet\", \"Das war gut!\", \"Sie fahrt ein grunes Auto.\"]\n",
    "\n",
    "batch = tokenizer(X_train, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0])\n",
      "['NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    label_ids = torch.argmax(outputs.logits, dim=1)\n",
    "    print(label_ids)\n",
    "    labels = [model.config.id2label[label_id] for label_id in label_ids.tolist()]\n",
    "    print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0765b9855a7659208f612bcb0b9b5e473e80eecc03acde40f135996d767af958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
