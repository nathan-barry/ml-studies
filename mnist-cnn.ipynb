{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and std of the pixels in the dataset\n",
    "mean_gray = 0.1307\n",
    "stddev_gray = 0.3081\n",
    "\n",
    "# Transform the images to tensors and normalize\n",
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                 transforms.Normalize((mean_gray,),\n",
    "                                 (stddev_gray,))])\n",
    "\n",
    "# Load our datasets\n",
    "train_dataset = datasets.MNIST(root = './data',\n",
    "                               train = True,\n",
    "                               transform = transforms)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = './data',\n",
    "                               train = False,\n",
    "                               transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "random_image = train_dataset[20][0].numpy() * stddev_gray + mean_gray\n",
    "plt.imshow(random_image.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[20][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} images in the training set'.format(len(train_dataset)))\n",
    "print('There are {} images in the test set'.format(len(test_dataset)))\n",
    "print('There are {} batches in the train loader'.format(len(train_loader)))\n",
    "print('There are {} batches in the testloader'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # First CNN Layer\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1) # output 28x28\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8) # Apply to each feature map (out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2) # output 14x14\n",
    "\n",
    "        # Second CNN Layer\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(in_features=1568, out_features=600) # 7*7*32 = 1568\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First CNN Layer\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        # Second CNN Layer\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        # Flatten the outputs\n",
    "        out = out.view(-1, 1568)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand what's happening\n",
    "iteration = 0\n",
    "correct = 0\n",
    "\n",
    "for i,(inputs,labels) in enumerate (train_loader):\n",
    "\n",
    "    if CUDA:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    print(\"For one iteration, this is what happens:\")\n",
    "    print(\"Input Shape: \",inputs.shape)\n",
    "    print(\"Labels Shape: \",labels.shape)\n",
    "    output = model(inputs)\n",
    "    print(\"Outputs Shape: \",output.shape)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(\"Predicted Shape: \",predicted.shape)\n",
    "    print(\"Predicted Tensor: \")\n",
    "    print(predicted)\n",
    "    correct += (predicted == labels).sum()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the CNN\n",
    "epochs = 10\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    iter_loss = 0.0\n",
    "\n",
    "    model.train() # Need this since we're using dropout\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        # Forward Prop\n",
    "        outputs = model(inputs)         \n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(outputs, labels)  \n",
    "        iter_loss += loss.item()\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad() # Clear the gradients\n",
    "        loss.backward() # Calculates the gradients\n",
    "        optimizer.step() # Updates the weights\n",
    "\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "\n",
    "    # Record the training loss and training accuracy\n",
    "    train_loss.append(iter_loss / iterations)\n",
    "    train_accuracy.append(100 * correct / len(train_dataset))\n",
    "\n",
    "    # Testing\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    testing_loss = 0.0\n",
    "\n",
    "    model.eval()         \n",
    "\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        # Forward Prop\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(outputs, labels)\n",
    "        testing_loss += loss.item()\n",
    "\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "    \n",
    "    # Record the testing loss and testing accuracy\n",
    "    test_loss.append(testing_loss / iterations)\n",
    "    test_accuracy.append(100 * correct / len(test_dataset))\n",
    "\n",
    "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Testing Loss: {:.3f}, Testing Acc: {:.3f}'\n",
    "           .format(epoch+1, epochs, train_loss[-1], train_accuracy[-1], \n",
    "             test_loss[-1], test_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_loss, label=\"Training Loss\")\n",
    "plt.plot(test_loss, label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_accuracy, label=\"Training Accuracy\")\n",
    "plt.plot(test_accuracy, label=\"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_dataset[30][0].resize_((1, 1, 28, 28)) # (batch_size, channels, height, width)\n",
    "label = test_dataset[30][1]\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "    img = img.cuda()\n",
    "\n",
    "output = model(img)\n",
    "_, predicted = torch.max(output, 1)\n",
    "print(f\"Prediction is: {predicted.item()}\")\n",
    "print(f\"Actual is: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0765b9855a7659208f612bcb0b9b5e473e80eecc03acde40f135996d767af958"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
